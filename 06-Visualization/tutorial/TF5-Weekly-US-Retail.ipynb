{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1413d6",
   "metadata": {},
   "source": [
    "# Category 5\n",
    "\n",
    "Sequence (시계열) 데이터 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfad319",
   "metadata": {},
   "source": [
    "## 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33158dd8",
   "metadata": {},
   "source": [
    "1. GPU 옵션 켜져 있는지 확인할 것!!! (수정 - 노트설정 - 하드웨어설정 (GPU))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0989fb2",
   "metadata": {},
   "source": [
    "## 순서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133fcd4",
   "metadata": {},
   "source": [
    "1. **import**: 필요한 모듈 import\n",
    "2. **전처리**: 학습에 필요한 데이터 전처리를 수행합니다.\n",
    "3. **모델링(model)**: 모델을 정의합니다.\n",
    "4. **컴파일(compile)**: 모델을 생성합니다.\n",
    "5. **학습 (fit)**: 모델을 학습시킵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41716c06",
   "metadata": {},
   "source": [
    "## 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a909b6c",
   "metadata": {},
   "source": [
    "Build and train a neural network to predict the time indexed variable of the univariate US diesel prices (On - Highway) All types for the period of 1994 - 2021.\n",
    "\n",
    "Using a **window of past 10 observations of 1 feature** , train the model to predict the **next 10 observations** of that feature.\n",
    "\n",
    "---\n",
    "\n",
    "HINT: If you follow all the rules mentioned above and throughout this\n",
    "question while training your neural network, there is a possibility that a\n",
    "validation **MAE of approximately 0.02 or less on the normalized validation\n",
    "dataset** may fetch you top marks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3422951",
   "metadata": {},
   "source": [
    "## 실습 예제 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4407fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Weekly_U.S.Diesel_Retail_Prices.csv',\n",
       " <http.client.HTTPMessage at 0x7ff3b4446790>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "url = 'https://www.dropbox.com/s/eduk281didil1km/Weekly_U.S.Diesel_Retail_Prices.csv?dl=1'\n",
    "urllib.request.urlretrieve(url, 'Weekly_U.S.Diesel_Retail_Prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea2ea7",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf69d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function normalizes the dataset using min max scaling.\n",
    "# DO NOT CHANGE THIS CODE\n",
    "def normalize_series(data, min, max):\n",
    "    data = data - min\n",
    "    data = data / max\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80820e55",
   "metadata": {},
   "source": [
    "### Windowed Dataset 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f85f8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT CHANGE THIS.\n",
    "def windowed_dataset(series, batch_size, n_past=10, n_future=10, shift=1):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
    "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5294aaa0",
   "metadata": {},
   "source": [
    "### Dataset 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb8adcad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly U.S. No 2 Diesel Retail Prices Dollars per Gallon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Week of</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1994-03-21</th>\n",
       "      <td>1.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-03-28</th>\n",
       "      <td>1.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-04</th>\n",
       "      <td>1.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-11</th>\n",
       "      <td>1.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-18</th>\n",
       "      <td>1.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-25</th>\n",
       "      <td>1.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-02</th>\n",
       "      <td>1.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-09</th>\n",
       "      <td>1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-16</th>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-23</th>\n",
       "      <td>1.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-05-30</th>\n",
       "      <td>1.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-06</th>\n",
       "      <td>1.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-13</th>\n",
       "      <td>1.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-20</th>\n",
       "      <td>1.103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-27</th>\n",
       "      <td>1.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-04</th>\n",
       "      <td>1.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-11</th>\n",
       "      <td>1.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-18</th>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-07-25</th>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-08-01</th>\n",
       "      <td>1.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Weekly U.S. No 2 Diesel Retail Prices Dollars per Gallon\n",
       "Week of                                                             \n",
       "1994-03-21                                              1.106       \n",
       "1994-03-28                                              1.107       \n",
       "1994-04-04                                              1.109       \n",
       "1994-04-11                                              1.108       \n",
       "1994-04-18                                              1.105       \n",
       "1994-04-25                                              1.106       \n",
       "1994-05-02                                              1.104       \n",
       "1994-05-09                                              1.101       \n",
       "1994-05-16                                              1.099       \n",
       "1994-05-23                                              1.099       \n",
       "1994-05-30                                              1.098       \n",
       "1994-06-06                                              1.101       \n",
       "1994-06-13                                              1.098       \n",
       "1994-06-20                                              1.103       \n",
       "1994-06-27                                              1.108       \n",
       "1994-07-04                                              1.109       \n",
       "1994-07-11                                              1.110       \n",
       "1994-07-18                                              1.111       \n",
       "1994-07-25                                              1.111       \n",
       "1994-08-01                                              1.116       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Weekly_U.S.Diesel_Retail_Prices.csv', infer_datetime_format=True, index_col='Week of', header=0)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec1f883e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 특성 정의\n",
    "N_FEATURES = len(df.columns)\n",
    "N_FEATURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66090bba",
   "metadata": {},
   "source": [
    "### 정규화 및 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26502285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 코드\n",
    "data = df.values\n",
    "data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
    "\n",
    "# 데이터 분할\n",
    "SPLIT_TIME = int(len(data) * 0.8) # DO NOT CHANGE THIS\n",
    "x_train = data[:SPLIT_TIME]\n",
    "x_valid = data[SPLIT_TIME:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e75e029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32  # 배치사이즈\n",
    "N_PAST = 10      # 과거 데이터 (X)\n",
    "N_FUTURE = 10    # 미래 데이터 (Y)\n",
    "SHIFT = 1        # SHIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e49b63",
   "metadata": {},
   "source": [
    "### train / validation set 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91292427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 10:44:34.482313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.483096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.488760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.489548: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.490342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.491082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.492596: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-20 10:44:34.738546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.739297: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.740053: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.740940: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.741676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:34.742372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.247447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.248214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.248962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.249670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.250411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.251106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20137 MB memory:  -> device: 0, name: GeForce RTX 3090, pci bus id: 0000:21:00.0, compute capability: 8.6\n",
      "2021-10-20 10:44:35.251421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-20 10:44:35.252141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22312 MB memory:  -> device: 1, name: GeForce RTX 3090, pci bus id: 0000:49:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
    "                             n_past=N_PAST, n_future=N_FUTURE,\n",
    "                             shift=SHIFT)\n",
    "\n",
    "valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
    "                             n_past=N_PAST, n_future=N_FUTURE,\n",
    "                             shift=SHIFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb69e7",
   "metadata": {},
   "source": [
    "### 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9a2ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    Conv1D(filters=32, kernel_size=5, padding='causal', activation='relu', input_shape=[N_PAST, 1]),\n",
    "    Bidirectional(LSTM(32, return_sequences=True)),\n",
    "    Bidirectional(LSTM(32, return_sequences=True)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(N_FEATURES)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b0cde",
   "metadata": {},
   "source": [
    "### 체크포인트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7c72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model/my_checkpoint.ckpt'\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_path,\n",
    "                             save_weights_only=True,\n",
    "                             save_best_only=True,\n",
    "                             monitor='val_mae',\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d88f17",
   "metadata": {},
   "source": [
    "### 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a51acd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ada3688",
   "metadata": {},
   "source": [
    "### 학습(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f3a59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 10:44:36.030763: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 10:44:39.140766: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8101\n",
      "2021-10-20 10:44:40.211047: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 5s 30ms/step - loss: 0.0396 - mae: 0.2180 - val_loss: 0.0328 - val_mae: 0.2493\n",
      "\n",
      "Epoch 00001: val_mae improved from inf to 0.24934, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 2/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0173 - mae: 0.1359 - val_loss: 0.0099 - val_mae: 0.1291\n",
      "\n",
      "Epoch 00002: val_mae improved from 0.24934 to 0.12913, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 3/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0071 - mae: 0.0994 - val_loss: 0.0021 - val_mae: 0.0503\n",
      "\n",
      "Epoch 00003: val_mae improved from 0.12913 to 0.05032, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 4/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0922 - val_loss: 0.0016 - val_mae: 0.0452\n",
      "\n",
      "Epoch 00004: val_mae improved from 0.05032 to 0.04525, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 5/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0839 - val_loss: 0.0015 - val_mae: 0.0438\n",
      "\n",
      "Epoch 00005: val_mae improved from 0.04525 to 0.04376, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 6/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0737 - val_loss: 0.0014 - val_mae: 0.0422\n",
      "\n",
      "Epoch 00006: val_mae improved from 0.04376 to 0.04221, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 7/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0031 - mae: 0.0644 - val_loss: 0.0013 - val_mae: 0.0408\n",
      "\n",
      "Epoch 00007: val_mae improved from 0.04221 to 0.04077, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 8/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0026 - mae: 0.0568 - val_loss: 0.0013 - val_mae: 0.0394\n",
      "\n",
      "Epoch 00008: val_mae improved from 0.04077 to 0.03938, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 9/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0022 - mae: 0.0507 - val_loss: 0.0012 - val_mae: 0.0379\n",
      "\n",
      "Epoch 00009: val_mae improved from 0.03938 to 0.03791, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 10/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0020 - mae: 0.0462 - val_loss: 0.0011 - val_mae: 0.0367\n",
      "\n",
      "Epoch 00010: val_mae improved from 0.03791 to 0.03670, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 11/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0019 - mae: 0.0431 - val_loss: 0.0011 - val_mae: 0.0354\n",
      "\n",
      "Epoch 00011: val_mae improved from 0.03670 to 0.03540, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 12/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0018 - mae: 0.0408 - val_loss: 0.0010 - val_mae: 0.0343\n",
      "\n",
      "Epoch 00012: val_mae improved from 0.03540 to 0.03427, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 13/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0017 - mae: 0.0393 - val_loss: 9.5328e-04 - val_mae: 0.0331\n",
      "\n",
      "Epoch 00013: val_mae improved from 0.03427 to 0.03306, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 14/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0016 - mae: 0.0381 - val_loss: 9.0939e-04 - val_mae: 0.0321\n",
      "\n",
      "Epoch 00014: val_mae improved from 0.03306 to 0.03212, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 15/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0016 - mae: 0.0372 - val_loss: 8.6865e-04 - val_mae: 0.0312\n",
      "\n",
      "Epoch 00015: val_mae improved from 0.03212 to 0.03118, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 16/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0015 - mae: 0.0364 - val_loss: 8.3801e-04 - val_mae: 0.0304\n",
      "\n",
      "Epoch 00016: val_mae improved from 0.03118 to 0.03044, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 17/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0015 - mae: 0.0358 - val_loss: 8.1119e-04 - val_mae: 0.0298\n",
      "\n",
      "Epoch 00017: val_mae improved from 0.03044 to 0.02977, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 18/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0015 - mae: 0.0353 - val_loss: 7.9065e-04 - val_mae: 0.0292\n",
      "\n",
      "Epoch 00018: val_mae improved from 0.02977 to 0.02924, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 19/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0350 - val_loss: 7.7382e-04 - val_mae: 0.0288\n",
      "\n",
      "Epoch 00019: val_mae improved from 0.02924 to 0.02882, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 20/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0015 - mae: 0.0346 - val_loss: 7.5996e-04 - val_mae: 0.0285\n",
      "\n",
      "Epoch 00020: val_mae improved from 0.02882 to 0.02848, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 21/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0343 - val_loss: 7.4875e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00021: val_mae improved from 0.02848 to 0.02821, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 22/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0341 - val_loss: 7.3942e-04 - val_mae: 0.0280\n",
      "\n",
      "Epoch 00022: val_mae improved from 0.02821 to 0.02800, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 23/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0014 - mae: 0.0339 - val_loss: 7.3146e-04 - val_mae: 0.0278\n",
      "\n",
      "Epoch 00023: val_mae improved from 0.02800 to 0.02781, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 24/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0337 - val_loss: 7.2475e-04 - val_mae: 0.0277\n",
      "\n",
      "Epoch 00024: val_mae improved from 0.02781 to 0.02766, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 25/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0335 - val_loss: 7.1893e-04 - val_mae: 0.0275\n",
      "\n",
      "Epoch 00025: val_mae improved from 0.02766 to 0.02753, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 26/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0333 - val_loss: 7.1404e-04 - val_mae: 0.0274\n",
      "\n",
      "Epoch 00026: val_mae improved from 0.02753 to 0.02743, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 27/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0331 - val_loss: 7.0986e-04 - val_mae: 0.0273\n",
      "\n",
      "Epoch 00027: val_mae improved from 0.02743 to 0.02734, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 28/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0330 - val_loss: 7.0645e-04 - val_mae: 0.0273\n",
      "\n",
      "Epoch 00028: val_mae improved from 0.02734 to 0.02728, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 29/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0328 - val_loss: 7.0365e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00029: val_mae improved from 0.02728 to 0.02723, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 30/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0326 - val_loss: 7.0123e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00030: val_mae improved from 0.02723 to 0.02719, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 31/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0325 - val_loss: 6.9907e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00031: val_mae improved from 0.02719 to 0.02716, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 32/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0014 - mae: 0.0323 - val_loss: 6.9715e-04 - val_mae: 0.0271\n",
      "\n",
      "Epoch 00032: val_mae improved from 0.02716 to 0.02715, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 33/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0321 - val_loss: 6.9572e-04 - val_mae: 0.0271\n",
      "\n",
      "Epoch 00033: val_mae improved from 0.02715 to 0.02714, saving model to model/my_checkpoint.ckpt\n",
      "Epoch 34/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0320 - val_loss: 6.9470e-04 - val_mae: 0.0271\n",
      "\n",
      "Epoch 00034: val_mae did not improve from 0.02714\n",
      "Epoch 35/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0319 - val_loss: 6.9384e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00035: val_mae did not improve from 0.02714\n",
      "Epoch 36/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0318 - val_loss: 6.9304e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00036: val_mae did not improve from 0.02714\n",
      "Epoch 37/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0317 - val_loss: 6.9222e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00037: val_mae did not improve from 0.02714\n",
      "Epoch 38/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0316 - val_loss: 6.9188e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00038: val_mae did not improve from 0.02714\n",
      "Epoch 39/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0315 - val_loss: 6.9172e-04 - val_mae: 0.0272\n",
      "\n",
      "Epoch 00039: val_mae did not improve from 0.02714\n",
      "Epoch 40/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0315 - val_loss: 6.9177e-04 - val_mae: 0.0273\n",
      "\n",
      "Epoch 00040: val_mae did not improve from 0.02714\n",
      "Epoch 41/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0314 - val_loss: 6.9184e-04 - val_mae: 0.0273\n",
      "\n",
      "Epoch 00041: val_mae did not improve from 0.02714\n",
      "Epoch 42/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0313 - val_loss: 6.9194e-04 - val_mae: 0.0273\n",
      "\n",
      "Epoch 00042: val_mae did not improve from 0.02714\n",
      "Epoch 43/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0312 - val_loss: 6.9282e-04 - val_mae: 0.0274\n",
      "\n",
      "Epoch 00043: val_mae did not improve from 0.02714\n",
      "Epoch 44/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0312 - val_loss: 6.9305e-04 - val_mae: 0.0274\n",
      "\n",
      "Epoch 00044: val_mae did not improve from 0.02714\n",
      "Epoch 45/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 6.9334e-04 - val_mae: 0.0275\n",
      "\n",
      "Epoch 00045: val_mae did not improve from 0.02714\n",
      "Epoch 46/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0311 - val_loss: 6.9365e-04 - val_mae: 0.0275\n",
      "\n",
      "Epoch 00046: val_mae did not improve from 0.02714\n",
      "Epoch 47/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 6.9374e-04 - val_mae: 0.0275\n",
      "\n",
      "Epoch 00047: val_mae did not improve from 0.02714\n",
      "Epoch 48/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 6.9400e-04 - val_mae: 0.0275\n",
      "\n",
      "Epoch 00048: val_mae did not improve from 0.02714\n",
      "Epoch 49/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0013 - mae: 0.0310 - val_loss: 6.9403e-04 - val_mae: 0.0276\n",
      "\n",
      "Epoch 00049: val_mae did not improve from 0.02714\n",
      "Epoch 50/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0309 - val_loss: 6.9423e-04 - val_mae: 0.0276\n",
      "\n",
      "Epoch 00050: val_mae did not improve from 0.02714\n",
      "Epoch 51/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0309 - val_loss: 6.9442e-04 - val_mae: 0.0276\n",
      "\n",
      "Epoch 00051: val_mae did not improve from 0.02714\n",
      "Epoch 52/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 6.9552e-04 - val_mae: 0.0277\n",
      "\n",
      "Epoch 00052: val_mae did not improve from 0.02714\n",
      "Epoch 53/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 6.9662e-04 - val_mae: 0.0277\n",
      "\n",
      "Epoch 00053: val_mae did not improve from 0.02714\n",
      "Epoch 54/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 6.9946e-04 - val_mae: 0.0278\n",
      "\n",
      "Epoch 00054: val_mae did not improve from 0.02714\n",
      "Epoch 55/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0308 - val_loss: 6.9917e-04 - val_mae: 0.0278\n",
      "\n",
      "Epoch 00055: val_mae did not improve from 0.02714\n",
      "Epoch 56/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0307 - val_loss: 7.0131e-04 - val_mae: 0.0279\n",
      "\n",
      "Epoch 00056: val_mae did not improve from 0.02714\n",
      "Epoch 57/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0013 - mae: 0.0307 - val_loss: 7.0429e-04 - val_mae: 0.0280\n",
      "\n",
      "Epoch 00057: val_mae did not improve from 0.02714\n",
      "Epoch 58/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0013 - mae: 0.0306 - val_loss: 7.0303e-04 - val_mae: 0.0280\n",
      "\n",
      "Epoch 00058: val_mae did not improve from 0.02714\n",
      "Epoch 59/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0013 - mae: 0.0305 - val_loss: 7.0370e-04 - val_mae: 0.0280\n",
      "\n",
      "Epoch 00059: val_mae did not improve from 0.02714\n",
      "Epoch 60/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0305 - val_loss: 7.0536e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00060: val_mae did not improve from 0.02714\n",
      "Epoch 61/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0012 - mae: 0.0305 - val_loss: 7.0455e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00061: val_mae did not improve from 0.02714\n",
      "Epoch 62/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0012 - mae: 0.0304 - val_loss: 7.0507e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00062: val_mae did not improve from 0.02714\n",
      "Epoch 63/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0012 - mae: 0.0304 - val_loss: 7.0355e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00063: val_mae did not improve from 0.02714\n",
      "Epoch 64/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0303 - val_loss: 7.0409e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00064: val_mae did not improve from 0.02714\n",
      "Epoch 65/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0303 - val_loss: 7.0336e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00065: val_mae did not improve from 0.02714\n",
      "Epoch 66/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0303 - val_loss: 7.0286e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00066: val_mae did not improve from 0.02714\n",
      "Epoch 67/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0302 - val_loss: 7.0240e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00067: val_mae did not improve from 0.02714\n",
      "Epoch 68/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0302 - val_loss: 7.0170e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00068: val_mae did not improve from 0.02714\n",
      "Epoch 69/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0302 - val_loss: 7.0073e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00069: val_mae did not improve from 0.02714\n",
      "Epoch 70/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0301 - val_loss: 7.0071e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00070: val_mae did not improve from 0.02714\n",
      "Epoch 71/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0301 - val_loss: 7.0170e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00071: val_mae did not improve from 0.02714\n",
      "Epoch 72/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 6.9979e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00072: val_mae did not improve from 0.02714\n",
      "Epoch 73/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 7.0065e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00073: val_mae did not improve from 0.02714\n",
      "Epoch 74/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0300 - val_loss: 7.0142e-04 - val_mae: 0.0281\n",
      "\n",
      "Epoch 00074: val_mae did not improve from 0.02714\n",
      "Epoch 75/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0299 - val_loss: 7.0258e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00075: val_mae did not improve from 0.02714\n",
      "Epoch 76/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0299 - val_loss: 7.0188e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00076: val_mae did not improve from 0.02714\n",
      "Epoch 77/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0298 - val_loss: 7.0282e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00077: val_mae did not improve from 0.02714\n",
      "Epoch 78/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0298 - val_loss: 7.0385e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00078: val_mae did not improve from 0.02714\n",
      "Epoch 79/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0298 - val_loss: 7.0397e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00079: val_mae did not improve from 0.02714\n",
      "Epoch 80/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0297 - val_loss: 7.0288e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00080: val_mae did not improve from 0.02714\n",
      "Epoch 81/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0297 - val_loss: 7.0200e-04 - val_mae: 0.0282\n",
      "\n",
      "Epoch 00081: val_mae did not improve from 0.02714\n",
      "Epoch 82/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0296 - val_loss: 7.0308e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00082: val_mae did not improve from 0.02714\n",
      "Epoch 83/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0296 - val_loss: 7.0201e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00083: val_mae did not improve from 0.02714\n",
      "Epoch 84/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0295 - val_loss: 7.0226e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00084: val_mae did not improve from 0.02714\n",
      "Epoch 85/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0295 - val_loss: 7.0185e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00085: val_mae did not improve from 0.02714\n",
      "Epoch 86/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0295 - val_loss: 7.0206e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00086: val_mae did not improve from 0.02714\n",
      "Epoch 87/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0294 - val_loss: 7.0211e-04 - val_mae: 0.0283\n",
      "\n",
      "Epoch 00087: val_mae did not improve from 0.02714\n",
      "Epoch 88/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0012 - mae: 0.0294 - val_loss: 7.0280e-04 - val_mae: 0.0284\n",
      "\n",
      "Epoch 00088: val_mae did not improve from 0.02714\n",
      "Epoch 89/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0293 - val_loss: 7.0357e-04 - val_mae: 0.0284\n",
      "\n",
      "Epoch 00089: val_mae did not improve from 0.02714\n",
      "Epoch 90/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0293 - val_loss: 7.0365e-04 - val_mae: 0.0284\n",
      "\n",
      "Epoch 00090: val_mae did not improve from 0.02714\n",
      "Epoch 91/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mae: 0.0292 - val_loss: 7.0350e-04 - val_mae: 0.0285\n",
      "\n",
      "Epoch 00091: val_mae did not improve from 0.02714\n",
      "Epoch 92/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mae: 0.0292 - val_loss: 7.0451e-04 - val_mae: 0.0285\n",
      "\n",
      "Epoch 00092: val_mae did not improve from 0.02714\n",
      "Epoch 93/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0291 - val_loss: 7.0406e-04 - val_mae: 0.0285\n",
      "\n",
      "Epoch 00093: val_mae did not improve from 0.02714\n",
      "Epoch 94/100\n",
      "35/35 [==============================] - 0s 9ms/step - loss: 0.0011 - mae: 0.0291 - val_loss: 7.0542e-04 - val_mae: 0.0286\n",
      "\n",
      "Epoch 00094: val_mae did not improve from 0.02714\n",
      "Epoch 95/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0291 - val_loss: 7.0656e-04 - val_mae: 0.0286\n",
      "\n",
      "Epoch 00095: val_mae did not improve from 0.02714\n",
      "Epoch 96/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0290 - val_loss: 7.0824e-04 - val_mae: 0.0287\n",
      "\n",
      "Epoch 00096: val_mae did not improve from 0.02714\n",
      "Epoch 97/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0290 - val_loss: 7.0992e-04 - val_mae: 0.0287\n",
      "\n",
      "Epoch 00097: val_mae did not improve from 0.02714\n",
      "Epoch 98/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0290 - val_loss: 7.1181e-04 - val_mae: 0.0288\n",
      "\n",
      "Epoch 00098: val_mae did not improve from 0.02714\n",
      "Epoch 99/100\n",
      "35/35 [==============================] - 0s 8ms/step - loss: 0.0011 - mae: 0.0289 - val_loss: 7.1669e-04 - val_mae: 0.0290\n",
      "\n",
      "Epoch 00099: val_mae did not improve from 0.02714\n",
      "Epoch 100/100\n",
      "35/35 [==============================] - 0s 7ms/step - loss: 0.0011 - mae: 0.0289 - val_loss: 7.1968e-04 - val_mae: 0.0291\n",
      "\n",
      "Epoch 00100: val_mae did not improve from 0.02714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff3b41b2050>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set,\n",
    "          validation_data=(valid_set),\n",
    "          epochs=100,\n",
    "          callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f6196d",
   "metadata": {},
   "source": [
    "### 가중치 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4e2057a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff2cc110610>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
